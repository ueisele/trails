{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norwegian Trails Data Exploration\n",
    "\n",
    "**Goal**: Understand the actual structure and content of Turrutebasen data from Geonorge before building abstractions.\n",
    "\n",
    "**Data Source**: Geonorge/Kartverket - Norwegian government's official trail database (Turrutebasen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Our minimal modules\n",
    "from trails.io.sources.geonorge import Source as GeonorgeSource\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Geonorge Data\n",
    "\n",
    "First, let's load the data and see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Geonorge source\n",
    "geonorge = GeonorgeSource()\n",
    "\n",
    "# Show metadata about the source\n",
    "print(\"Data Source Information:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset: Turrutebasen\")\n",
    "print(\"Provider: Kartverket (Norwegian Mapping Authority)\")\n",
    "print(\"License: CC BY 4.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the data\n",
    "# This will either load from cache or download from Geonorge\n",
    "try:\n",
    "    trail_data = geonorge.load_turrutebasen()\n",
    "    print(\"\\nData loaded successfully!\")\n",
    "\n",
    "    # Extract layers\n",
    "    print(f\"\\nFound {len(trail_data.spatial_layers)} spatial layers:\")\n",
    "    for layer_name, gdf in trail_data.spatial_layers.items():\n",
    "        print(f\"  - {layer_name}: {len(gdf)} features\")\n",
    "\n",
    "    print(f\"\\nFound {len(trail_data.attribute_tables)} attribute tables:\")\n",
    "    for table_name, df in trail_data.attribute_tables.items():\n",
    "        print(f\"  - {table_name}: {len(df)} rows\")\n",
    "\n",
    "    # For compatibility with rest of notebook\n",
    "    data = trail_data.spatial_layers\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nData not found: {e}\")\n",
    "    print(\"\\nThe data will be downloaded automatically on first run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Layer Structure\n",
    "\n",
    "Let's examine each layer in detail to understand what data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed exploration of each layer\n",
    "if \"data\" in locals() and isinstance(data, dict):\n",
    "    layer_summary = {}\n",
    "\n",
    "    for layer_name, gdf in data.items():\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"LAYER: {layer_name}\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        # Basic info\n",
    "        print(\"\\nBasic Information:\")\n",
    "        print(f\"  Shape: {gdf.shape}\")\n",
    "        print(f\"  CRS: {gdf.crs}\")\n",
    "\n",
    "        # Geometry info\n",
    "        print(\"\\nGeometry Information:\")\n",
    "        if not gdf.empty and \"geometry\" in gdf.columns:\n",
    "            geom_types = gdf.geometry.geom_type.unique()\n",
    "            print(f\"  Geometry types: {geom_types}\")\n",
    "            print(f\"  Total bounds: {gdf.total_bounds}\")\n",
    "\n",
    "        # Store summary\n",
    "        layer_summary[layer_name] = {\n",
    "            \"shape\": gdf.shape,\n",
    "            \"crs\": str(gdf.crs),\n",
    "            \"columns\": list(gdf.columns),\n",
    "        }\n",
    "\n",
    "        # Show first few records\n",
    "        print(\"\\nFirst 2 records:\")\n",
    "        print(gdf.head(2))\n",
    "else:\n",
    "    print(\"Please load the data first (run the cell above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Column Analysis\n",
    "\n",
    "Let's analyze the columns in each layer to understand what attributes are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze columns for each layer\n",
    "if \"data\" in locals() and isinstance(data, dict):\n",
    "    for layer_name, gdf in data.items():\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"LAYER: {layer_name} - Column Analysis\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        # Exclude geometry column\n",
    "        columns = [col for col in gdf.columns if col != \"geometry\"]\n",
    "\n",
    "        print(f\"\\nTotal columns (excluding geometry): {len(columns)}\")\n",
    "        print(\"\\nColumn details:\")\n",
    "\n",
    "        for col in columns:\n",
    "            # Basic info\n",
    "            dtype = gdf[col].dtype\n",
    "            non_null = gdf[col].notna().sum()\n",
    "            null_pct = (1 - non_null / len(gdf)) * 100\n",
    "\n",
    "            print(f\"\\n  {col}:\")\n",
    "            print(f\"    Type: {dtype}\")\n",
    "            print(f\"    Non-null: {non_null}/{len(gdf)} ({100 - null_pct:.1f}% complete)\")\n",
    "\n",
    "            # For categorical/text columns, show unique values if not too many\n",
    "            if dtype == \"object\" and non_null > 0:\n",
    "                unique_count = gdf[col].nunique()\n",
    "                print(f\"    Unique values: {unique_count}\")\n",
    "\n",
    "                if unique_count <= 10:\n",
    "                    values = gdf[col].dropna().unique()\n",
    "                    print(f\"    Values: {list(values)}\")\n",
    "                elif unique_count <= 20:\n",
    "                    top_values = gdf[col].value_counts().head(5)\n",
    "                    print(\"    Top 5 values:\")\n",
    "                    for val, count in top_values.items():\n",
    "                        print(f\"      - {val}: {count}\")\n",
    "\n",
    "            # For numeric columns, show statistics\n",
    "            elif dtype in [\"int64\", \"float64\"] and non_null > 0:\n",
    "                print(f\"    Min: {gdf[col].min()}\")\n",
    "                print(f\"    Max: {gdf[col].max()}\")\n",
    "                print(f\"    Mean: {gdf[col].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Trail Layers\n",
    "\n",
    "Let's identify which layers contain actual trail data (LineString geometries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trail layers (with line geometries)\n",
    "if \"data\" in locals() and isinstance(data, dict):\n",
    "    trail_layers = {}\n",
    "    point_layers = {}\n",
    "    other_layers = {}\n",
    "\n",
    "    for layer_name, gdf in data.items():\n",
    "        if gdf.empty:\n",
    "            other_layers[layer_name] = gdf\n",
    "            continue\n",
    "\n",
    "        # Check geometry type\n",
    "        geom_types = gdf.geometry.geom_type.unique()\n",
    "\n",
    "        if any(gt in [\"LineString\", \"MultiLineString\"] for gt in geom_types):\n",
    "            trail_layers[layer_name] = gdf\n",
    "        elif any(gt in [\"Point\", \"MultiPoint\"] for gt in geom_types):\n",
    "            point_layers[layer_name] = gdf\n",
    "        else:\n",
    "            other_layers[layer_name] = gdf\n",
    "\n",
    "    print(\"Layer Classification:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nTrail Layers (Lines): {len(trail_layers)}\")\n",
    "    for name, gdf in trail_layers.items():\n",
    "        print(f\"  - {name}: {len(gdf)} features\")\n",
    "\n",
    "    print(f\"\\nPoint Layers (Facilities): {len(point_layers)}\")\n",
    "    for name, gdf in point_layers.items():\n",
    "        print(f\"  - {name}: {len(gdf)} features\")\n",
    "\n",
    "    if other_layers:\n",
    "        print(f\"\\nOther Layers: {len(other_layers)}\")\n",
    "        for name, gdf in other_layers.items():\n",
    "            print(f\"  - {name}: {len(gdf)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Focus on Main Trail Layer\n",
    "\n",
    "Let's analyze the main trail layer in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and analyze the main trail layer\n",
    "if \"trail_layers\" in locals() and trail_layers:\n",
    "    # Get the largest trail layer or first one\n",
    "    main_layer_name = max(trail_layers.keys(), key=lambda x: len(trail_layers[x]))\n",
    "    trails = trail_layers[main_layer_name]\n",
    "\n",
    "    print(f\"Selected main trail layer: {main_layer_name}\")\n",
    "    print(f\"Total features: {len(trails)}\")\n",
    "    print(\"\\nColumns in this layer:\")\n",
    "    for col in trails.columns:\n",
    "        if col != \"geometry\":\n",
    "            print(f\"  - {col}\")\n",
    "\n",
    "    # Try to identify key fields based on common patterns\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Attempting to identify key fields...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    field_patterns = {\n",
    "        \"name\": [\"navn\", \"rutenavn\", \"name\", \"title\"],\n",
    "        \"type\": [\"rutetype\", \"type\", \"kategori\", \"category\", \"spesial\"],\n",
    "        \"difficulty\": [\"vanskgrad\", \"gradering\", \"difficulty\", \"grade\"],\n",
    "        \"length\": [\"lengde\", \"length\", \"distance\"],\n",
    "        \"municipality\": [\"kommune\", \"kommunenr\", \"municipality\"],\n",
    "        \"county\": [\"fylke\", \"fylkesnr\", \"county\"],\n",
    "        \"marking\": [\"merking\", \"marking\", \"skilting\"],\n",
    "        \"maintenance\": [\"vedlikehold\", \"vedlikeholdsansvarlig\", \"maintenance\", \"eier\"],\n",
    "        \"id\": [\"lokalid\", \"objectid\", \"id\", \"gid\"],\n",
    "    }\n",
    "\n",
    "    found_fields = {}\n",
    "    for field_type, patterns in field_patterns.items():\n",
    "        for col in trails.columns:\n",
    "            col_lower = col.lower()\n",
    "            if any(pattern in col_lower for pattern in patterns):\n",
    "                found_fields[field_type] = col\n",
    "                print(f\"  {field_type}: {col}\")\n",
    "\n",
    "                # Show sample values\n",
    "                if col in trails.columns:\n",
    "                    non_null = trails[col].dropna()\n",
    "                    if len(non_null) > 0:\n",
    "                        if trails[col].dtype == \"object\":\n",
    "                            unique = non_null.nunique()\n",
    "                            print(f\"    → {unique} unique values\")\n",
    "                            if unique <= 5:\n",
    "                                print(f\"    → Values: {list(non_null.unique())}\")\n",
    "                        else:\n",
    "                            print(f\"    → Range: {non_null.min()} to {non_null.max()}\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nIdentified {len(found_fields)} potential key fields\")\n",
    "else:\n",
    "    print(\"No trail layers found. Please check the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess data quality for the main trail layer\n",
    "if \"trails\" in locals():\n",
    "    print(\"Data Quality Report\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Completeness analysis\n",
    "    completeness_data = []\n",
    "    for col in trails.columns:\n",
    "        if col != \"geometry\":\n",
    "            non_null = trails[col].notna().sum()\n",
    "            completeness = (non_null / len(trails)) * 100\n",
    "            completeness_data.append(\n",
    "                {\n",
    "                    \"Field\": col,\n",
    "                    \"Non_Null\": non_null,\n",
    "                    \"Null\": len(trails) - non_null,\n",
    "                    \"Completeness_%\": completeness,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    completeness_df = pd.DataFrame(completeness_data)\n",
    "    completeness_df = completeness_df.sort_values(\"Completeness_%\", ascending=False)\n",
    "\n",
    "    print(\"\\nField Completeness (Top 10 most complete):\")\n",
    "    print(completeness_df.head(10))\n",
    "\n",
    "    print(\"\\nFields with poor completeness (<50%):\")\n",
    "    poor_fields = completeness_df[completeness_df[\"Completeness_%\"] < 50]\n",
    "    if not poor_fields.empty:\n",
    "        print(poor_fields)\n",
    "    else:\n",
    "        print(\"  All fields have >50% completeness\")\n",
    "\n",
    "    # Geometry quality\n",
    "    print(\"\\nGeometry Quality:\")\n",
    "    print(f\"  Valid geometries: {trails.geometry.is_valid.sum()} / {len(trails)}\")\n",
    "    print(f\"  Empty geometries: {trails.geometry.is_empty.sum()}\")\n",
    "    print(f\"  Simple geometries: {trails.geometry.is_simple.sum()} / {len(trails)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spatial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spatial distribution\n",
    "if \"trails\" in locals():\n",
    "    print(\"Spatial Distribution Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Get bounds\n",
    "    bounds = trails.total_bounds\n",
    "    print(\"\\nSpatial extent (minx, miny, maxx, maxy):\")\n",
    "    print(f\"  {bounds}\")\n",
    "    print(f\"\\nCRS: {trails.crs}\")\n",
    "\n",
    "    # If we have administrative fields, analyze distribution\n",
    "    if \"found_fields\" in locals():\n",
    "        if \"county\" in found_fields:\n",
    "            county_col = found_fields[\"county\"]\n",
    "            print(f\"\\nDistribution by {county_col}:\")\n",
    "            county_stats = trails[county_col].value_counts().head(10)\n",
    "            for county, count in county_stats.items():\n",
    "                print(f\"  {county}: {count} trails ({count / len(trails) * 100:.1f}%)\")\n",
    "\n",
    "        if \"type\" in found_fields:\n",
    "            type_col = found_fields[\"type\"]\n",
    "            print(f\"\\nDistribution by {type_col}:\")\n",
    "            type_stats = trails[type_col].value_counts()\n",
    "            for trail_type, count in type_stats.items():\n",
    "                print(f\"  {trail_type}: {count} trails ({count / len(trails) * 100:.1f}%)\")\n",
    "\n",
    "    # Calculate total length\n",
    "    print(\"\\nLength Analysis:\")\n",
    "    if \"found_fields\" in locals() and \"length\" in found_fields:\n",
    "        length_col = found_fields[\"length\"]\n",
    "        total_length = trails[length_col].sum()\n",
    "        avg_length = trails[length_col].mean()\n",
    "        print(f\"  Total length from '{length_col}': {total_length:,.0f} (units unknown)\")\n",
    "        print(f\"  Average length: {avg_length:,.0f}\")\n",
    "    else:\n",
    "        print(\"  Calculating from geometry...\")\n",
    "        trails[\"calculated_length\"] = trails.geometry.length\n",
    "        total_calc_length = trails[\"calculated_length\"].sum()\n",
    "        print(f\"  Total calculated length: {total_calc_length:,.0f} (CRS units)\")\n",
    "        print(f\"  Average calculated length: {trails['calculated_length'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic visualizations\n",
    "if \"trails\" in locals():\n",
    "    # Plot all trails\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Plot trails with a simple color\n",
    "    trails.plot(ax=ax, linewidth=0.5, alpha=0.6, color=\"darkgreen\")\n",
    "\n",
    "    ax.set_title(f\"Norwegian Trails from Geonorge ({len(trails)} features)\", fontsize=14)\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add CRS info\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        f\"CRS: {trails.crs}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # If we have categories, show distribution\n",
    "    if \"found_fields\" in locals() and \"type\" in found_fields:\n",
    "        type_col = found_fields[\"type\"]\n",
    "        type_counts = trails[type_col].value_counts()\n",
    "\n",
    "        if len(type_counts) > 0:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "            # Bar chart\n",
    "            type_counts.head(10).plot(kind=\"bar\", ax=ax1, color=\"forestgreen\")\n",
    "            ax1.set_title(\"Trail Types Distribution (Top 10)\")\n",
    "            ax1.set_xlabel(\"Trail Type\")\n",
    "            ax1.set_ylabel(\"Count\")\n",
    "            ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "            # Pie chart for top 5\n",
    "            type_counts.head(5).plot(kind=\"pie\", ax=ax2, autopct=\"%1.1f%%\")\n",
    "            ax2.set_title(\"Top 5 Trail Types\")\n",
    "            ax2.set_ylabel(\"\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sample data for testing\n",
    "if \"trails\" in locals():\n",
    "    # Create output directory\n",
    "    output_dir = Path(\"data/samples\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Export a sample\n",
    "    sample_size = min(100, len(trails))\n",
    "    sample = trails.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Save as GeoJSON\n",
    "    output_file = output_dir / \"geonorge_trails_sample.geojson\"\n",
    "    sample.to_file(output_file, driver=\"GeoJSON\")\n",
    "    print(f\"Exported {sample_size} sample trails to {output_file}\")\n",
    "\n",
    "    # Save field summary\n",
    "    if \"found_fields\" in locals():\n",
    "        summary = {\n",
    "            \"source\": \"Geonorge/Kartverket\",\n",
    "            \"layer\": main_layer_name,\n",
    "            \"total_features\": len(trails),\n",
    "            \"sample_size\": sample_size,\n",
    "            \"crs\": str(trails.crs),\n",
    "            \"identified_fields\": found_fields,\n",
    "            \"all_columns\": list(trails.columns),\n",
    "            \"completeness\": completeness_df.to_dict(\"records\")\n",
    "            if \"completeness_df\" in locals()\n",
    "            else None,\n",
    "        }\n",
    "\n",
    "        summary_file = output_dir / \"geonorge_field_summary.json\"\n",
    "        with open(summary_file, \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        print(f\"Saved field summary to {summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "if \"data\" in locals():\n",
    "    print(\"EXPLORATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\n1. DATA STRUCTURE:\")\n",
    "    if isinstance(data, dict):\n",
    "        print(f\"   - Total layers: {len(data)}\")\n",
    "        for layer, gdf in data.items():\n",
    "            print(f\"   - {layer}: {len(gdf)} features\")\n",
    "\n",
    "    if \"trails\" in locals():\n",
    "        print(f\"\\n2. MAIN TRAIL LAYER: {main_layer_name}\")\n",
    "        print(f\"   - Total trails: {len(trails)}\")\n",
    "        print(f\"   - CRS: {trails.crs}\")\n",
    "        print(f\"   - Columns: {len(trails.columns)}\")\n",
    "\n",
    "        if \"found_fields\" in locals():\n",
    "            print(\"\\n3. IDENTIFIED KEY FIELDS:\")\n",
    "            for field_type, col_name in found_fields.items():\n",
    "                print(f\"   - {field_type}: {col_name}\")\n",
    "\n",
    "        print(\"\\n4. DATA QUALITY:\")\n",
    "        print(f\"   - Valid geometries: {trails.geometry.is_valid.sum()}/{len(trails)}\")\n",
    "        if \"completeness_df\" in locals():\n",
    "            high_quality = completeness_df[completeness_df[\"Completeness_%\"] > 90]\n",
    "            print(f\"   - Fields with >90% completeness: {len(high_quality)}\")\n",
    "\n",
    "        print(\"\\n5. RECOMMENDATIONS FOR IMPLEMENTATION:\")\n",
    "        print(\"   Based on the exploration, consider:\")\n",
    "        print(\"   - [Add specific recommendations based on actual findings]\")\n",
    "\n",
    "        # Check for expected vs actual fields\n",
    "        print(\"\\n6. NOTABLE OBSERVATIONS:\")\n",
    "        if \"found_fields\" in locals():\n",
    "            if \"difficulty\" not in found_fields:\n",
    "                print(\"   ⚠ No difficulty field found (expected 'vanskgrad')\")\n",
    "            if \"name\" not in found_fields:\n",
    "                print(\"   ⚠ No name field found\")\n",
    "            if \"type\" in found_fields:\n",
    "                print(f\"   ✓ Trail type field found: {found_fields['type']}\")\n",
    "else:\n",
    "    print(\"No data loaded. Please download and load the data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on the exploration findings:\n",
    "\n",
    "1. **Build specific processing modules** for the actual data structure found\n",
    "2. **Create appropriate mappings** for trail types and categories\n",
    "3. **Design analysis functions** that work with available fields\n",
    "4. **Plan visualization approach** based on data quality and completeness\n",
    "\n",
    "The actual implementation should be adapted based on what we discovered in this exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
