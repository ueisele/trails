{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norwegian Trails Data Exploration\n",
    "\n",
    "**Goal**: Understand the actual structure and content of Turrutebasen data from Geonorge before building abstractions.\n",
    "\n",
    "**Data Source**: Geonorge/Kartverket - Norwegian government's official trail database (Turrutebasen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Our minimal modules\n",
    "from trails.io.sources.geonorge import Source as GeonorgeSource\n",
    "from trails.io.sources.language import Language\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Project paths\n",
    "project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "cache_dir = project_root / \".cache\"\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Cache directory: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Geonorge Data\n",
    "\n",
    "First, let's load the data and see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Geonorge source and load data\n",
    "geonorge = GeonorgeSource(cache_dir=str(cache_dir))\n",
    "\n",
    "# Load with English translations (use Language.NO for Norwegian)\n",
    "trail_data = geonorge.load_turrutebasen(language=Language.EN)\n",
    "print(\"Data Source Information:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: {trail_data.metadata.dataset_name}\")\n",
    "print(f\"Provider: {trail_data.metadata.provider}\")\n",
    "print(f\"License: {trail_data.metadata.license}\")\n",
    "print(f\"Dataset ID: {trail_data.metadata.dataset_id}\")\n",
    "print(f\"Description: {trail_data.metadata.description}\")\n",
    "print(f\"Attribution: {trail_data.metadata.attribution}\")\n",
    "\n",
    "print(f\"\\nData loaded successfully from: {trail_data.source_url}\")\n",
    "print(f\"Version: {trail_data.version}\")\n",
    "print(f\"Language: {trail_data.language.value}\")\n",
    "print(f\"CRS: {trail_data.crs}\")\n",
    "print(f\"Total features: {trail_data.total_features}\")\n",
    "\n",
    "# Layers and columns are now automatically translated\n",
    "print(f\"\\nFound {len(trail_data.spatial_layers)} spatial layers:\")\n",
    "for layer_name, gdf in trail_data.spatial_layers.items():\n",
    "    print(f\"  - {layer_name}: {len(gdf)} features\")\n",
    "\n",
    "print(f\"\\nFound {len(trail_data.attribute_tables)} attribute tables:\")\n",
    "for table_name, df in trail_data.attribute_tables.items():\n",
    "    print(f\"  - {table_name}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Complete Layer Analysis\n",
    "\n",
    "Let's examine each layer in detail, analyzing both structure and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete analysis of all layers\n",
    "print(\"=\" * 80)\n",
    "print(\"SPATIAL LAYERS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "layer_summary = {}\n",
    "\n",
    "for layer_name, gdf in trail_data.spatial_layers.items():\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"LAYER: {layer_name}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Basic info\n",
    "    print(\"\\nBasic Information:\")\n",
    "    print(f\"  Shape: {gdf.shape}\")\n",
    "    print(f\"  CRS: {gdf.crs}\")\n",
    "\n",
    "    # Geometry info\n",
    "    print(\"\\nGeometry Information:\")\n",
    "    if not gdf.empty and \"geometry\" in gdf.columns:\n",
    "        geom_types = gdf.geometry.geom_type.unique()\n",
    "        print(f\"  Geometry types: {geom_types}\")\n",
    "        print(f\"  Total bounds: {gdf.total_bounds}\")\n",
    "\n",
    "    # Column analysis\n",
    "    columns = [col for col in gdf.columns if col != \"geometry\"]\n",
    "    print(f\"\\nColumn Analysis ({len(columns)} columns):\")\n",
    "\n",
    "    for col in columns:\n",
    "        dtype = gdf[col].dtype\n",
    "        non_null_count = gdf[col].notna().sum()\n",
    "        null_pct = (1 - non_null_count / len(gdf)) * 100\n",
    "\n",
    "        print(f\"\\n  {col}:\")\n",
    "        print(f\"    Type: {dtype}\")\n",
    "        print(f\"    Non-null: {non_null_count}/{len(gdf)} ({100 - null_pct:.1f}% complete)\")\n",
    "\n",
    "        # For categorical/text columns\n",
    "        if dtype == \"object\" and non_null_count > 0:\n",
    "            unique_count = gdf[col].nunique()\n",
    "            print(f\"    Unique values: {unique_count}\")\n",
    "\n",
    "            if unique_count <= 5:\n",
    "                values = gdf[col].dropna().unique()\n",
    "                # Values are already expanded and translated\n",
    "                print(f\"    Values: {list(values)}\")\n",
    "            elif unique_count > 5:\n",
    "                top_values = gdf[col].value_counts().head(5)\n",
    "                print(\"    Top 5 values:\")\n",
    "                for val, count in top_values.items():\n",
    "                    # Values are already expanded and translated\n",
    "                    print(f\"      - {val}: {count}\")\n",
    "\n",
    "        # For numeric columns\n",
    "        elif dtype in [\"int32\", \"int64\", \"float64\"] and non_null_count > 0:\n",
    "            print(f\"    Min: {gdf[col].min()}\")\n",
    "            print(f\"    Max: {gdf[col].max()}\")\n",
    "            print(f\"    Mean: {gdf[col].mean():.2f}\")\n",
    "\n",
    "        # For datetime columns\n",
    "        elif dtype in [\"datetime64[ms, UTC]\"] and non_null_count > 0:\n",
    "            print(f\"    Min: {gdf[col].min()}\")\n",
    "            print(f\"    Max: {gdf[col].max()}\")\n",
    "\n",
    "    # Store summary\n",
    "    layer_summary[layer_name] = {\n",
    "        \"shape\": gdf.shape,\n",
    "        \"crs\": str(gdf.crs),\n",
    "        \"columns\": list(gdf.columns),\n",
    "        \"geometry_types\": list(geom_types) if not gdf.empty else [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ATTRIBUTE TABLES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for table_name, df in trail_data.attribute_tables.items():\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"TABLE: {table_name}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Basic info\n",
    "    print(\"\\nBasic Information:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "    # Column analysis\n",
    "    print(f\"\\nColumn Analysis ({len(df.columns)} columns):\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        non_null_count = df[col].notna().sum()\n",
    "        null_pct = (1 - non_null_count / len(df)) * 100\n",
    "\n",
    "        print(f\"\\n  {col}:\")\n",
    "        print(f\"    Type: {dtype}\")\n",
    "        print(f\"    Non-null: {non_null_count}/{len(df)} ({100 - null_pct:.1f}% complete)\")\n",
    "\n",
    "        # For categorical/text columns\n",
    "        if dtype == \"object\" and non_null_count > 0:\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"    Unique values: {unique_count}\")\n",
    "\n",
    "            if unique_count <= 5:\n",
    "                values = df[col].dropna().unique()\n",
    "                # Values are already expanded and translated\n",
    "                print(f\"    Values: {list(values)}\")\n",
    "            elif unique_count > 5:\n",
    "                top_values = df[col].value_counts().head(5)\n",
    "                print(\"    Top 5 values:\")\n",
    "                for val, count in top_values.items():\n",
    "                    # Values are already expanded and translated\n",
    "                    print(f\"      - {val}: {count}\")\n",
    "\n",
    "        # For numeric columns\n",
    "        elif dtype in [\"int32\", \"int64\", \"float64\"] and non_null_count > 0:\n",
    "            print(f\"    Min: {df[col].min()}\")\n",
    "            print(f\"    Max: {df[col].max()}\")\n",
    "            mean_val = df[col].mean()\n",
    "            if not pd.isna(mean_val):\n",
    "                print(f\"    Mean: {mean_val:.2f}\")\n",
    "\n",
    "        # For datetime columns\n",
    "        elif dtype in [\"datetime64[ms, UTC]\"] and non_null_count > 0:\n",
    "            print(f\"    Min: {df[col].min()}\")\n",
    "            print(f\"    Max: {df[col].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Trail Layers\n",
    "\n",
    "Let's identify which layers contain actual trail data (LineString geometries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trail layers (with line geometries)\n",
    "trail_layers = {}\n",
    "point_layers = {}\n",
    "other_layers = {}\n",
    "\n",
    "for layer_name, gdf in trail_data.spatial_layers.items():\n",
    "    if gdf.empty:\n",
    "        other_layers[layer_name] = gdf\n",
    "        continue\n",
    "\n",
    "    # Check geometry type\n",
    "    geom_types = gdf.geometry.geom_type.unique()\n",
    "\n",
    "    if any(gt in [\"LineString\", \"MultiLineString\"] for gt in geom_types):\n",
    "        trail_layers[layer_name] = gdf\n",
    "    elif any(gt in [\"Point\", \"MultiPoint\"] for gt in geom_types):\n",
    "        point_layers[layer_name] = gdf\n",
    "    else:\n",
    "        other_layers[layer_name] = gdf\n",
    "\n",
    "print(\"Layer Classification:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTrail Layers (Lines): {len(trail_layers)}\")\n",
    "for name, gdf in trail_layers.items():\n",
    "    print(f\"  - {name}: {len(gdf)} features\")\n",
    "\n",
    "print(f\"\\nPoint Layers (Facilities): {len(point_layers)}\")\n",
    "for name, gdf in point_layers.items():\n",
    "    print(f\"  - {name}: {len(gdf)} features\")\n",
    "\n",
    "if other_layers:\n",
    "    print(f\"\\nOther Layers: {len(other_layers)}\")\n",
    "    for name, gdf in other_layers.items():\n",
    "        print(f\"  - {name}: {len(gdf)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Focus on Hiking Trail Layer\n",
    "\n",
    "Let's analyze the hiking trail layer in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess data quality for the main trail layer\n",
    "# Note: layer name depends on language - \"hiking_trail_centerline\" in English\n",
    "hiking_trail_layer = \"hiking_trail_centerline\" if trail_data.language == Language.EN else \"fotrute_senterlinje\"\n",
    "\n",
    "if hiking_trail_layer in trail_data.spatial_layers:\n",
    "    trails = trail_data.spatial_layers[hiking_trail_layer]\n",
    "\n",
    "    print(\"Data Quality Report\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Completeness analysis\n",
    "    completeness_data = []\n",
    "    for col in trails.columns:\n",
    "        if col != \"geometry\":\n",
    "            non_null = trails[col].notna().sum()\n",
    "            completeness = (non_null / len(trails)) * 100\n",
    "            completeness_data.append(\n",
    "                {\n",
    "                    \"Field\": col,\n",
    "                    \"Non_Null\": non_null,\n",
    "                    \"Null\": len(trails) - non_null,\n",
    "                    \"Completeness_%\": completeness,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    completeness_df = pd.DataFrame(completeness_data)\n",
    "    completeness_df = completeness_df.sort_values(\"Completeness_%\", ascending=False)\n",
    "\n",
    "    print(\"\\nField Completeness (Top 10 most complete):\")\n",
    "    print(completeness_df.head(10))\n",
    "\n",
    "    print(\"\\nFields with poor completeness (<50%):\")\n",
    "    poor_fields = completeness_df[completeness_df[\"Completeness_%\"] < 50]\n",
    "    if not poor_fields.empty:\n",
    "        print(poor_fields)\n",
    "    else:\n",
    "        print(\"  All fields have >50% completeness\")\n",
    "\n",
    "    # Geometry quality\n",
    "    print(\"\\nGeometry Quality:\")\n",
    "    print(f\"  Valid geometries: {trails.geometry.is_valid.sum()} / {len(trails)}\")\n",
    "    print(f\"  Empty geometries: {trails.geometry.is_empty.sum()}\")\n",
    "    print(f\"  Simple geometries: {trails.geometry.is_simple.sum()} / {len(trails)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatial Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spatial distribution for main trail layer\n",
    "from trails.utils.geo import calculate_lengths_meters\n",
    "\n",
    "hiking_trail_layer = \"hiking_trail_centerline\" if trail_data.language == Language.EN else \"fotrute_senterlinje\"\n",
    "\n",
    "if hiking_trail_layer in trail_data.spatial_layers:\n",
    "    trails = trail_data.spatial_layers[hiking_trail_layer]\n",
    "\n",
    "    print(\"Spatial Distribution Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Get bounds\n",
    "    bounds = trails.total_bounds\n",
    "    print(\"\\nSpatial extent (minx, miny, maxx, maxy):\")\n",
    "    print(f\"  {bounds}\")\n",
    "    print(f\"\\nCRS: {trails.crs}\")\n",
    "\n",
    "    # Analyze by object_type if it exists (translated column name)\n",
    "    objtype_col = \"object_type\" if trail_data.language == Language.EN else \"objtype\"\n",
    "    if objtype_col in trails.columns:\n",
    "        print(f\"\\nDistribution by {objtype_col}:\")\n",
    "        type_stats = trails[objtype_col].value_counts()\n",
    "        for trail_type, count in type_stats.items():\n",
    "            # Values are already expanded and translated\n",
    "            print(f\"  {trail_type}: {count} trails ({count / len(trails) * 100:.1f}%)\")\n",
    "\n",
    "    # Calculate total length in meters (optimized batch calculation)\n",
    "    print(\"\\nLength Analysis:\")\n",
    "    print(\"  Calculating lengths ...\")\n",
    "\n",
    "    # Use the new optimized batch function\n",
    "    trails_copy = trails.copy()\n",
    "    trails_copy[\"length_meters\"] = calculate_lengths_meters(trails_copy)\n",
    "\n",
    "    total_length = trails_copy[\"length_meters\"].sum()\n",
    "    avg_length = trails_copy[\"length_meters\"].mean()\n",
    "    median_length = trails_copy[\"length_meters\"].median()\n",
    "\n",
    "    # Print in kilometers for readability\n",
    "    print(f\"  Total length: {total_length / 1000:,.1f} km\")\n",
    "    print(f\"  Average trail length: {avg_length / 1000:.2f} km\")\n",
    "    print(f\"  Median trail length: {median_length / 1000:.2f} km\")\n",
    "\n",
    "    # Show distribution of trail lengths\n",
    "    print(\"\\nTrail Length Distribution:\")\n",
    "    print(f\"  Shortest trail: {trails_copy['length_meters'].min() / 1000:.3f} km\")\n",
    "    print(f\"  Longest trail: {trails_copy['length_meters'].max() / 1000:.1f} km\")\n",
    "\n",
    "    # Length categories (using meters for calculation, displaying in km)\n",
    "    bins = [0, 1000, 5000, 10000, 20000, float(\"inf\")]\n",
    "    labels = [\"<1km\", \"1-5km\", \"5-10km\", \"10-20km\", \">20km\"]\n",
    "    trails_copy[\"length_category\"] = pd.cut(trails_copy[\"length_meters\"], bins=bins, labels=labels)\n",
    "\n",
    "    print(\"\\nTrails by length category:\")\n",
    "    for category in labels:\n",
    "        count = (trails_copy[\"length_category\"] == category).sum()\n",
    "        pct = count / len(trails_copy) * 100\n",
    "        print(f\"  {category}: {count:,} trails ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic visualizations for main trail layer\n",
    "hiking_trail_layer = \"hiking_trail_centerline\" if trail_data.language == Language.EN else \"fotrute_senterlinje\"\n",
    "\n",
    "if hiking_trail_layer in trail_data.spatial_layers:\n",
    "    trails = trail_data.spatial_layers[hiking_trail_layer]\n",
    "\n",
    "    # Plot all trails\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Plot trails with a simple color\n",
    "    trails.plot(ax=ax, linewidth=0.5, alpha=0.6, color=\"darkgreen\")\n",
    "\n",
    "    ax.set_title(f\"Norwegian Hiking Trails ({len(trails)} features)\", fontsize=14)\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add CRS info\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        f\"CRS: {trails.crs}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # If we have object type, show distribution\n",
    "    objtype_col = \"object_type\" if trail_data.language == Language.EN else \"objtype\"\n",
    "    if objtype_col in trails.columns:\n",
    "        type_counts = trails[objtype_col].value_counts()\n",
    "\n",
    "        if len(type_counts) > 0:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "            # Bar chart\n",
    "            type_counts.head(10).plot(kind=\"bar\", ax=ax1, color=\"forestgreen\")\n",
    "            ax1.set_title(\"Trail Types Distribution (Top 10)\")\n",
    "            ax1.set_xlabel(\"Trail Type\")\n",
    "            ax1.set_ylabel(\"Count\")\n",
    "            ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "            # Pie chart for top 5\n",
    "            type_counts.head(5).plot(kind=\"pie\", ax=ax2, autopct=\"%1.1f%%\")\n",
    "            ax2.set_title(\"Top 5 Trail Types\")\n",
    "            ax2.set_ylabel(\"\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
